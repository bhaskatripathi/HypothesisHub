{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNme6zJcGVXYUd9HHiTb08M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhaskatripathi/HypothesisHub/blob/main/Hypothesis_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hypothesis Hub**: *An AI Tool for Automated Research Question and Hypothesis Generation from a given Scientific Literature*"
      ],
      "metadata": {
        "id": "CiJGS2kfWEhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m1H_uP4zi5M",
        "outputId": "48a8f19e-91b8-4a1e-bfb7-a3fada3e0b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting OpenAI\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.138-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.7/520.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from OpenAI) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from OpenAI) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Collecting SQLAlchemy<2,>=1\n",
            "  Downloading SQLAlchemy-1.4.47-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->OpenAI) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->OpenAI) (22.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect>=0.4.0\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->OpenAI) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->OpenAI) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->OpenAI) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Collecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, OpenAI, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.9\n",
            "    Uninstalling SQLAlchemy-2.0.9:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.9\n",
            "Successfully installed OpenAI-0.27.4 SQLAlchemy-1.4.47 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.138 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.8.0 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "pip install OpenAI langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import SimpleMemory\n",
        "import os"
      ],
      "metadata": {
        "id": "VwyIL17MVE0t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The following code generates three research questions and hypothesis (Ho,H1) for each of the research questions.**\n",
        "The code can be modified to address more research questions based on individual needs"
      ],
      "metadata": {
        "id": "euCjPxxhVDZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequence Diagram**"
      ],
      "metadata": {
        "id": "uDjBumR7Xf-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://raw.githubusercontent.com/bhaskatripathi/HypothesisHub/main/Sequence%20diagram.PNG')\n"
      ],
      "metadata": {
        "id": "xO5IJiUXVinn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "009d209e-8b39-4e5f-e2bd-1e525319c8e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/bhaskatripathi/HypothesisHub/main/Sequence%20diagram.PNG\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResearchAndHypothesisGenerator:\n",
        "    def __init__(self, openai_api_key):\n",
        "        self.llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key,model_name=\"text-davinci-003\")\n",
        "\n",
        "        research_question_template = \"\"\"Given the following text, generate three research questions related to the topic. Ensure that the research questions are clear, focused, and can be investigated using a scientific method. Each research question should ideally involve one or more variables that can be measured or manipulated. \n",
        "Text: {text}\n",
        "Examples of good research questions:\n",
        "- How does variable A affect variable B?\n",
        "- What is the relationship between variable X and variable Y?\n",
        "- To what extent does factor M influence outcome N?\n",
        "Research Question 1: \n",
        "Research Question 2: \n",
        "Research Question 3: \"\"\"\n",
        "        self.rq_prompt_template = PromptTemplate(input_variables=[\"text\"], template=research_question_template)\n",
        "        self.research_question_chain = LLMChain(\n",
        "            llm=self.llm, prompt=self.rq_prompt_template, output_key=\"research_questions\"\n",
        "        )\n",
        "\n",
        "        hypothesis_template = \"\"\"Given the research question \"{research_question}\", generate a null hypothesis (H0) and an alternate hypothesis (H1). The null hypothesis should represent the absence of an effect, relationship, or difference, while the alternate hypothesis should represent the presence of an effect, relationship, or difference. Ensure that hypotheses H0 and H1 are never the same for the research question \"{research_question}\". \n",
        "Null Hypothesis (H0):\n",
        "Alternate Hypothesis (H1):\"\"\"\n",
        "\n",
        "        self.hypothesis_prompt_template = PromptTemplate(input_variables=[\"research_question\"], template=hypothesis_template)\n",
        "        self.hypothesis_chain = LLMChain(\n",
        "            llm=self.llm, prompt=self.hypothesis_prompt_template, output_key=\"hypotheses\"\n",
        "        )\n",
        "\n",
        "    def generate_research_questions(self, user_text):\n",
        "        result = self.research_question_chain({\"text\": user_text})\n",
        "        research_questions = [rq.strip() for rq in result[\"research_questions\"].split('\\n') if rq.startswith('Research Question')]\n",
        "        return research_questions\n",
        "\n",
        "    def generate_hypotheses(self, research_questions):\n",
        "        hypotheses = []\n",
        "\n",
        "        for question in research_questions:\n",
        "            # Generate null hypothesis (H0)\n",
        "            h0_result = self.hypothesis_chain({\"research_question\": question, \"hypothesis_type\": \"null\"})\n",
        "            h0_lines = [line.strip() for line in h0_result[\"hypotheses\"].split('\\n') if line.strip()]\n",
        "            if len(h0_lines) > 0:\n",
        "                h0 = h0_lines[0]\n",
        "            else:\n",
        "                h0 = \"N/A\"\n",
        "\n",
        "            # Generate alternate hypothesis (H1)\n",
        "            h1_result = self.hypothesis_chain({\"research_question\": question, \"hypothesis_type\": \"alternate\"})\n",
        "            h1_lines = [line.strip() for line in h1_result[\"hypotheses\"].split('\\n') if line.strip()]\n",
        "            if len(h1_lines) > 0:\n",
        "                h1 = h1_lines[0]\n",
        "            else:\n",
        "                h1 = \"N/A\"\n",
        "\n",
        "            # Ensure H0 and H1 are different, generate new H1 if needed\n",
        "            while h1 == h0 or h1 == \"N/A\":\n",
        "                h1_result = self.hypothesis_chain({\"research_question\": question, \"hypothesis_type\": \"alternate\"})\n",
        "                h1_lines = [line.strip() for line in h1_result[\"hypotheses\"].split('\\n') if line.strip()]\n",
        "                if len(h1_lines) > 0:\n",
        "                    h1 = h1_lines[0]\n",
        "                else:\n",
        "                    h1 = \"N/A\"\n",
        "\n",
        "            hypotheses.append((h0, h1))\n",
        "\n",
        "        return hypotheses\n",
        "\n",
        "    def create_hypotheses(self, research_questions):\n",
        "        hypotheses = []\n",
        "\n",
        "        for question in research_questions:\n",
        "            result = self.hypothesis_chain({\"research_question\": question})\n",
        "            hypothesis_lines = [line.strip() for line in result[\"hypotheses\"].split('\\n') if line.strip()]\n",
        "\n",
        "            if len(hypothesis_lines) < 2:\n",
        "                # If we don't have two hypotheses, generate new hypotheses until we have both H0 and H1\n",
        "                while len(hypothesis_lines) < 2:\n",
        "                    result = self.hypothesis_chain({\"research_question\": question})\n",
        "                    hypothesis_lines = [line.strip() for line in result[\"hypotheses\"].split('\\n') if line.strip()]\n",
        "\n",
        "            h0 = hypothesis_lines[0]\n",
        "            h1 = hypothesis_lines[1]\n",
        "\n",
        "            # Ensure H0 and H1 are different, generate new hypotheses if needed\n",
        "            while h1 == h0:\n",
        "                result = self.hypothesis_chain({\"research_question\": question})\n",
        "                hypothesis_lines = [line.strip() for line in result[\"hypotheses\"].split('\\n') if line.strip()]\n",
        "                if len(hypothesis_lines) >= 2:\n",
        "                    h0 = hypothesis_lines[0]\n",
        "                    h1 = hypothesis_lines[1]\n",
        "\n",
        "            hypotheses.append((h0, h1))\n",
        "\n",
        "        return hypotheses\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_text = \"\"\"Objective: To identify the factors responsible for price inconsistencies across different major cryptocurrency exchanges .\n",
        "Our third objective is to determine the factors responsible for price inconsistencies across different major Bitcoin exchanges. \n",
        "To examine the pricing inconsistencies across various exchanges, the Spread (Bid/Ask difference) in the top 3 volume traded Crypto exchanges will be studied. \n",
        "Factors such as Exchange volume, exchange market size, transaction fee cost of exchange, Anti Money Laundering (AML) or Know Your Customer (KYC) requirement will also be considered among others. \n",
        "It is also expected that higher transaction volumes lead to a lower difference between the prices at which a Cryptocurrencies are traded across different exchanges. \n",
        "Comparative prices of one exchange to another by using regression and other appropriate techniques will be analyzed. \n",
        "    \"\"\"\n",
        "    os.environ[\"OPENAI_API_KEY\"] = #\"you_openai_api_key\"\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        "    generator = ResearchAndHypothesisGenerator(api_key)\n",
        "    print(\"RUNNING CHAIN OF THOUGHTS...:\")\n",
        "    research_questions = generator.generate_research_questions(user_text)\n",
        "    print(\"ORIGINAL TEXT:\")\n",
        "    print(user_text)\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    print(\"LIST OF REQSEARCH QUESTIONS:\")\n",
        "    for i, question in enumerate(research_questions):\n",
        "        print(f\"{i + 1}: {question}\")\n",
        "\n",
        "    hypotheses = generator.create_hypotheses(research_questions)\n",
        "    print(\"\\nLIST OF HYPOTHESIS:\")\n",
        "    for i, hypothesis_pair in enumerate(hypotheses):\n",
        "        print(f\"\\nRESEARCH QUESTION {i + 1}:\")\n",
        "        print(f\"NULL HYPOTHESIS (H0): {hypothesis_pair[0]}\")\n",
        "        print(f\"ALTERNATE HYPOTHESIS (H1): {hypothesis_pair[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsbXdyQ_5JYk",
        "outputId": "1b8c474b-85cb-4929-8e8c-5c8b07a1694a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUNNING CHAIN OF THOUGHTS...:\n",
            "ORIGINAL TEXT:\n",
            "Objective: To identify the factors responsible for price inconsistencies across different major cryptocurrency exchanges .\n",
            "Our third objective is to determine the factors responsible for price inconsistencies across different major Bitcoin exchanges. \n",
            "To examine the pricing inconsistencies across various exchanges, the Spread (Bid/Ask difference) in the top 3 volume traded Crypto exchanges will be studied. \n",
            "Factors such as Exchange volume, exchange market size, transaction fee cost of exchange, Anti Money Laundering (AML) or Know Your Customer (KYC) requirement will also be considered among others. \n",
            "It is also expected that higher transaction volumes lead to a lower difference between the prices at which a Cryptocurrencies are traded across different exchanges. \n",
            "Comparative prices of one exchange to another by using regression and other appropriate techniques will be analyzed. \n",
            "    \n",
            "\n",
            "\n",
            "LIST OF REQSEARCH QUESTIONS:\n",
            "1: Research Question 1: How does exchange volume affect the spread (Bid/Ask difference) of the top 3 volume traded crypto exchanges?\n",
            "2: Research Question 2: What is the relationship between exchange market size and the spread (Bid/Ask difference) of the top 3 volume traded crypto exchanges?\n",
            "3: Research Question 3: To what extent does the transaction fee cost of exchange influence the comparative prices of one exchange to another?\n",
            "\n",
            "LIST OF HYPOTHESIS:\n",
            "\n",
            "RESEARCH QUESTION 1:\n",
            "NULL HYPOTHESIS (H0): Null Hypothesis (H0): Exchange volume has no effect on the spread (Bid/Ask difference) of the top 3 volume traded crypto exchanges.\n",
            "ALTERNATE HYPOTHESIS (H1): Alternate Hypothesis (H1): Exchange volume has an effect on the spread (Bid/Ask difference) of the top 3 volume traded crypto exchanges.\n",
            "\n",
            "RESEARCH QUESTION 2:\n",
            "NULL HYPOTHESIS (H0): Null Hypothesis (H0): There is no relationship between exchange market size and the spread (Bid/Ask difference) of the top 3 volume traded crypto exchanges.\n",
            "ALTERNATE HYPOTHESIS (H1): Alternate Hypothesis (H1): There is a relationship between exchange market size and the spread (Bid/Ask difference) of the top 3 volume traded crypto exchanges.\n",
            "\n",
            "RESEARCH QUESTION 3:\n",
            "NULL HYPOTHESIS (H0): The transaction fee cost of exchange has no effect on the comparative prices of one exchange to another.\n",
            "ALTERNATE HYPOTHESIS (H1): The transaction fee cost of exchange has an effect on the comparative prices of one exchange to another.\n"
          ]
        }
      ]
    }
  ]
}